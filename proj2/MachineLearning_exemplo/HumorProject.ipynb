{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                               text  is_humor  \\\n",
      "0     9001  Finding out your ex got fat is like finding 20...         1   \n",
      "1     9002  For Brockmann, stereotypes imperil national se...         0   \n",
      "2     9003  A girl runs up to her mother with a pile of cr...         1   \n",
      "3     9004  gotta wonder if baseball still would've been c...         1   \n",
      "4     9005  When you're dreading getting in the shower cuz...         1   \n",
      "..     ...                                                ...       ...   \n",
      "995   9996  What do you call a black man on the moon? An a...         1   \n",
      "996   9997  when im picking someone up and they ask how lo...         1   \n",
      "997   9998  A black lesbian, an obese white neck-beard, an...         1   \n",
      "998   9999  and I recognize the need to use ALL of my plat...         0   \n",
      "999  10000  Get married so you can argue about fun things ...         1   \n",
      "\n",
      "     humor_rating  humor_controversy  offense_rating  \n",
      "0            2.20                0.0            0.90  \n",
      "1             NaN                NaN            0.35  \n",
      "2            2.80                1.0            0.10  \n",
      "3            2.15                0.0            0.00  \n",
      "4            2.25                0.0            0.35  \n",
      "..            ...                ...             ...  \n",
      "995          1.88                1.0            1.05  \n",
      "996          1.88                0.0            0.00  \n",
      "997          1.80                1.0            1.65  \n",
      "998           NaN                NaN            0.00  \n",
      "999          2.05                0.0            0.10  \n",
      "\n",
      "[1000 rows x 6 columns]\n",
      "\n",
      "Describe\n",
      "                 id     is_humor  humor_rating  humor_controversy  \\\n",
      "count   1000.000000  1000.000000    615.000000         615.000000   \n",
      "mean    9500.500000     0.615000      2.119171           0.453659   \n",
      "std      288.819436     0.486839      0.546133           0.498253   \n",
      "min     9001.000000     0.000000      0.270000           0.000000   \n",
      "25%     9250.750000     0.000000      1.790000           0.000000   \n",
      "50%     9500.500000     1.000000      2.120000           0.000000   \n",
      "75%     9750.250000     1.000000      2.500000           1.000000   \n",
      "max    10000.000000     1.000000      3.420000           1.000000   \n",
      "\n",
      "       offense_rating  \n",
      "count      1000.00000  \n",
      "mean          0.48030  \n",
      "std           0.83007  \n",
      "min           0.00000  \n",
      "25%           0.00000  \n",
      "50%           0.10000  \n",
      "75%           0.55000  \n",
      "max           4.65000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importing dataset\n",
    "dataset = pd.read_csv('../files/test.csv', nrows=1000)\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "print('\\nDescribe')\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare data: (ver em baixo)\n",
    "\n",
    "# Cleaning and tokenizing the text\n",
    "\n",
    "import nltk\n",
    "#from nltk import word_tokenize\n",
    "\n",
    "# tokenizes the first line of text of the dataset\n",
    "# tokens = word_tokenize(dataset.loc[0,'text'])\n",
    "# print(len(tokens))\n",
    "# print(tokens)\n",
    "\n",
    "# aggregate all the rows of the dataset in one corpus ('list')\n",
    "corpus = []\n",
    "for i in range(0,1000):\n",
    "    text = dataset['text'][i]\n",
    "    corpus.append(text)\n",
    "\n",
    "print(corpus)    \n",
    "\n",
    "#...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '10', '100', '12', '14', '1st', '20', '200', '2014', '30', '35', '50', '75', '80', 'able', 'about', 'access', 'accidentally', 'according', 'account', 'across', 'act', 'actually', 'advice', 'affected', 'afraid', 'african', 'after', 'again', 'against', 'age', 'ago', 'air', 'album', 'alcohol', 'alive', 'all', 'allowed', 'almost', 'alone', 'already', 'also', 'always', 'am', 'amazing', 'amazon', 'america', 'american', 'americans', 'amount', 'an', 'and', 'angels', 'angry', 'annoying', 'another', 'anxiety', 'any', 'anyone', 'anything', 'anyway', 'apart', 'are', 'aren', 'argument', 'around', 'arrested', 'as', 'asian', 'ask', 'asked', 'asking', 'asks', 'ass', 'at', 'attack', 'auntie', 'average', 'avoid', 'awareness', 'away', 'awkward', 'baby', 'back', 'bad', 'balance', 'ball', 'bank', 'bar', 'bathroom', 'be', 'beat', 'beautiful', 'became', 'because', 'become', 'bed', 'bee', 'been', 'beer', 'bees', 'before', 'beginning', 'being', 'believe', 'best', 'better', 'between', 'big', 'biggest', 'bike', 'biker', 'bill', 'bird', 'birds', 'birthday', 'bit', 'black', 'blessed', 'blind', 'blonde', 'blood', 'body', 'bomb', 'book', 'born', 'boss', 'both', 'bought', 'box', 'boy', 'boys', 'brain', 'brand', 'break', 'breaking', 'breath', 'bring', 'brings', 'bro', 'broken', 'brother', 'bug', 'building', 'bunch', 'business', 'busy', 'but', 'buy', 'buying', 'by', 'california', 'call', 'called', 'calling', 'calls', 'came', 'can', 'canadian', 'cancer', 'candy', 'cannibal', 'cannot', 'car', 'carbon', 'care', 'carrying', 'cars', 'cat', 'caucasian', 'caught', 'cause', 'chance', 'change', 'changed', 'charity', 'check', 'cheese', 'cheetahs', 'chef', 'chick', 'chicken', 'child', 'children', 'chinese', 'chirp', 'chocolate', 'choices', 'choose', 'chop', 'chosen', 'classic', 'close', 'coffee', 'cold', 'college', 'color', 'come', 'comes', 'comfortable', 'common', 'communicate', 'community', 'condoms', 'confused', 'considered', 'contains', 'context', 'control', 'conversation', 'cool', 'cop', 'corn', 'corny', 'cost', 'could', 'couldn', 'country', 'couples', 'crap', 'crazy', 'credit', 'crime', 'cry', 'cup', 'currently', 'cut', 'cute', 'dad', 'dads', 'damn', 'dance', 'dancing', 'dark', 'date', 'dating', 'daughter', 'day', 'days', 'dead', 'deaf', 'dealer', 'death', 'decisions', 'delicious', 'delivered', 'depression', 'deserve', 'did', 'didn', 'died', 'dies', 'difference', 'different', 'difficult', 'dinner', 'discovered', 'distance', 'do', 'doc', 'doctor', 'doctors', 'does', 'doesn', 'dog', 'dogs', 'doing', 'dolphins', 'don', 'done', 'door', 'down', 'dr', 'dream', 'drink', 'drinking', 'drop', 'dropped', 'drug', 'drugs', 'drunk', 'dude', 'due', 'during', 'each', 'earth', 'easy', 'eat', 'eating', 'eats', 'eight', 'else', 'end', 'english', 'enough', 'entire', 'episode', 'essential', 'etc', 'even', 'eventually', 'ever', 'every', 'everybody', 'everyone', 'everything', 'exciting', 'eyes', 'face', 'fact', 'factory', 'fake', 'fall', 'family', 'fat', 'father', 'favorite', 'fear', 'feel', 'feeling', 'feelings', 'feels', 'felt', 'female', 'feminist', 'feminists', 'few', 'fifth', 'fight', 'fighting', 'figure', 'fill', 'film', 'finally', 'find', 'finding', 'finds', 'finish', 'finished', 'fire', 'fired', 'first', 'fish', 'fit', 'five', 'fix', 'flies', 'floor', 'flow', 'fly', 'flying', 'focus', 'folks', 'follow', 'followers', 'following', 'food', 'fool', 'for', 'force', 'forces', 'forget', 'forgot', 'form', 'formally', 'fort', 'forties', 'forward', 'found', 'four', 'free', 'freedom', 'fridge', 'friend', 'friends', 'from', 'front', 'fry', 'fuck', 'fucking', 'fuel', 'full', 'fun', 'function', 'fund', 'funds', 'funeral', 'funny', 'future', 'game', 'garden', 'gave', 'gay', 'generation', 'genie', 'george', 'german', 'get', 'gets', 'getting', 'ghost', 'gift', 'ginger', 'girl', 'girlfriend', 'girls', 'give', 'given', 'gives', 'giving', 'glance', 'glass', 'gnc', 'go', 'god', 'goes', 'going', 'gold', 'golfer', 'gone', 'gonna', 'good', 'goodnight', 'google', 'got', 'government', 'grateful', 'gravity', 'gravy', 'great', 'greatest', 'greek', 'green', 'grenade', 'grief', 'groom', 'group', 'groups', 'grow', 'growing', 'grown', 'grows', 'guaranteed', 'guess', 'guests', 'guinness', 'gut', 'guy', 'guys', 'gym', 'had', 'hadn', 'haha', 'hair', 'half', 'hand', 'hands', 'happen', 'happening', 'happens', 'happier', 'happy', 'hard', 'harder', 'harvard', 'has', 'hate', 'haters', 'hath', 'have', 'haven', 'having', 'hawaii', 'hawking', 'he', 'head', 'headache', 'headaches', 'headed', 'heal', 'health', 'healthy', 'hear', 'heard', 'heart', 'hell', 'help', 'helped', 'helps', 'her', 'here', 'hers', 'hey', 'hide', 'hiding', 'high', 'higher', 'highest', 'hilarious', 'him', 'himself', 'his', 'hispanic', 'hit', 'ho', 'hold', 'holding', 'home', 'homeless', 'homophobic', 'honesty', 'honey', 'honeybees', 'hope', 'horror', 'horse', 'hospital', 'hot', 'hour', 'hours', 'house', 'how', 'hr', 'hug', 'human', 'humans', 'humidity', 'hunger', 'hungry', 'hurt', 'hurts', 'husband', 'ice', 'idea', 'identified', 'if', 'ii', 'image', 'imagine', 'immature', 'immediately', 'impact', 'impersonating', 'important', 'impress', 'impressing', 'in', 'income', 'increased', 'increases', 'increasing', 'incredible', 'india', 'indian', 'information', 'inmate', 'innocent', 'insects', 'inside', 'instagram', 'instead', 'interested', 'interesting', 'internet', 'interview', 'interviewer', 'into', 'invent', 'iphone', 'iqs', 'ireland', 'irish', 'iron', 'irritated', 'is', 'islam', 'island', 'isn', 'israel', 'issues', 'it', 'italian', 'its', 'james', 'jaws', 'jesus', 'jewish', 'jim', 'jnf', 'job', 'jobs', 'joke', 'jokes', 'jordan', 'journal', 'judge', 'junior', 'just', 'justice', 'keep', 'keeping', 'keeps', 'keller', 'kid', 'kidding', 'kids', 'kill', 'killer', 'killing', 'kills', 'kind', 'king', 'kitchen', 'kiwi', 'knew', 'knife', 'knock', 'know', 'known', 'knows', 'lack', 'ladies', 'lady', 'laid', 'land', 'language', 'large', 'last', 'later', 'laugh', 'laughed', 'laughing', 'law', 'lawn', 'lazy', 'lead', 'leaders', 'leading', 'leads', 'learn', 'learned', 'learning', 'least', 'leave', 'leaves', 'left', 'leftover', 'lesbian', 'less', 'let', 'letter', 'letters', 'levels', 'lgbt', 'lie', 'life', 'light', 'lightbulb', 'like', 'liked', 'likely', 'line', 'lion', 'listen', 'listening', 'lists', 'lit', 'literally', 'little', 'live', 'lives', 'living', 'll', 'local', 'loneliness', 'long', 'look', 'looked', 'looking', 'looks', 'lose', 'loss', 'lost', 'lot', 'lotion', 'lottery', 'loud', 'love', 'loved', 'lovely', 'loves', 'low', 'lower', 'lucky', 'lumberjack', 'lying', 'ma', 'machine', 'mad', 'made', 'magnesium', 'mail', 'main', 'make', 'makes', 'making', 'male', 'mama', 'man', 'mandalorian', 'many', 'march', 'marijuana', 'mario', 'mark', 'marriage', 'married', 'mars', 'mashed', 'masseuse', 'mat', 'match', 'matches', 'matter', 'matters', 'matthew', 'may', 'maybe', 'me', 'mean', 'means', 'medical', 'meet', 'mega', 'men', 'mental', 'message', 'met', 'meth', 'methods', 'mexican', 'mexico', 'michael', 'middle', 'might', 'miles', 'millennials', 'million', 'mind', 'mine', 'mint', 'mints', 'minute', 'minutes', 'miss', 'mistakes', 'mole', 'mom', 'momma', 'money', 'monkey', 'monster', 'month', 'months', 'moon', 'more', 'mormon', 'morning', 'most', 'mostly', 'mother', 'mothers', 'mouth', 'move', 'movie', 'movies', 'moving', 'much', 'mugger', 'murder', 'muscles', 'muscular', 'muslim', 'must', 'my', 'myself', 'naesm2016', 'naked', 'name', 'named', 'national', 'natural', 'navigate', 'nectar', 'need', 'needs', 'neighbor', 'neither', 'nervous', 'never', 'new', 'news', 'next', 'niacin', 'nice', 'nigeria', 'nigga', 'night', 'no', 'nobel', 'nobody', 'non', 'none', 'normal', 'north', 'nose', 'not', 'note', 'nothing', 'now', 'nuclear', 'number', 'nun', 'nuts', 'nyc', 'obama', 'obsession', 'ocean', 'of', 'off', 'office', 'officer', 'official', 'officially', 'often', 'oh', 'oil', 'ok', 'okay', 'okra', 'old', 'older', 'olympics', 'on', 'once', 'one', 'ones', 'online', 'only', 'open', 'or', 'orange', 'orcas', 'ordered', 'original', 'other', 'others', 'our', 'ourselves', 'out', 'over', 'overwhelmed', 'overwhelming', 'owe', 'own', 'owned', 'owners', 'packed', 'paid', 'pain', 'paper', 'park', 'part', 'parts', 'party', 'passed', 'past', 'peace', 'people', 'person', 'phone', 'picture', 'piece', 'pilot', 'pine', 'pirate', 'place', 'plane', 'planet', 'play', 'playing', 'please', 'podcast', 'point', 'police', 'political', 'pool', 'position', 'possible', 'post', 'potassium', 'potatoes', 'pour', 'powder', 'power', 'powered', 'prayers', 'predicted', 'pregnant', 'president', 'pressure', 'pretty', 'previous', 'pride', 'prison', 'private', 'prize', 'probably', 'problem', 'problems', 'process', 'produce', 'professional', 'professor', 'project', 'promise', 'promises', 'properly', 'protect', 'protein', 'psycho', 'pub', 'public', 'pull', 'pulled', 'pulls', 'punched', 'punishment', 'put', 'puts', 'putting', 'pyramid', 'queen', 'queer', 'question', 'questions', 'quickly', 'quiet', 'quit', 'quite', 'qué', 'rabbi', 'radical', 'radio', 'ran', 'range', 'rare', 'rather', 're', 'reach', 'read', 'reader', 'reading', 'ready', 'real', 'reality', 'realize', 'realized', 'really', 'reason', 'receive', 'received', 'recently', 'recipe', 'recognize', 'recommended', 'record', 'red', 'redcross', 'reduce', 'reduces', 'reducing', 'refused', 'regret', 'regular', 'regularly', 'relationship', 'relationships', 'released', 'religion', 'remained', 'remember', 'remembering', 'remind', 'replace', 'replied', 'replies', 'reply', 'research', 'researchers', 'resources', 'respect', 'respond', 'rest', 'restaurant', 'restaurants', 'result', 'retired', 'retweet', 'rhyme', 'rich', 'rid', 'ride', 'riding', 'right', 'ring', 'risk', 'road', 'robot', 'rofl', 'roman', 'room', 'rose', 'rough', 'rover', 'row', 'rules', 'run', 'running', 'sad', 'safe', 'safety', 'said', 'salad', 'same', 'sandwich', 'santa', 'save', 'saving', 'saw', 'say', 'saying', 'says', 'scared', 'scars', 'scene', 'school', 'schwarzenegger', 'scientists', 'screw', 'screwed', 'sea', 'season', 'seats', 'second', 'secretly', 'security', 'see', 'seeing', 'seek', 'seem', 'seems', 'seen', 'seized', 'self', 'sell', 'send', 'sending', 'sense', 'sentence', 'september', 'serial', 'series', 'serious', 'serving', 'sesame', 'set', 'settle', 'seven', 'sewage', 'sex', 'shade', 'shake', 'shakespeare', 'shampoo', 'share', 'shared', 'shark', 'sharp', 'she', 'shell', 'ship', 'shirts', 'shit', 'shoes', 'shoot', 'shooting', 'shop', 'shopping', 'shot', 'should', 'shouted', 'show', 'shower', 'shows', 'shut', 'sick', 'side', 'sign', 'signed', 'signs', 'silence', 'simple', 'simply', 'since', 'sing', 'singers', 'singing', 'single', 'siri', 'sit', 'sitting', 'situations', 'six', 'skin', 'sleep', 'sleeping', 'small', 'smell', 'smells', 'smile', 'smoke', 'smoking', 'snake', 'snakes', 'so', 'social', 'sofa', 'sold', 'some', 'somebody', 'someone', 'something', 'sometimes', 'son', 'song', 'soon', 'sore', 'sorry', 'soul', 'sound', 'sounds', 'south', 'southern', 'space', 'spanish', 'speak', 'special', 'species', 'specific', 'speed', 'spelling', 'spend', 'spending', 'spent', 'sperm', 'spider', 'spinning', 'splits', 'spn', 'sport', 'sports', 'spreading', 'squad', 'square', 'stairs', 'stand', 'standing', 'star', 'start', 'started', 'starting', 'state', 'states', 'statistics', 'stay', 'staying', 'steal', 'step', 'stephen', 'stereotype', 'stick', 'still', 'stole', 'stool', 'stop', 'stops', 'store', 'story', 'straight', 'street', 'strength', 'stress', 'stretch', 'strong', 'stronger', 'studies', 'stuff', 'stupid', 'successful', 'such', 'suck', 'sucked', 'sugar', 'suicide', 'summer', 'summit', 'sun', 'sunday', 'supernatura', 'support', 'sure', 'surgery', 'surround', 'swallow', 'sweet', 'swift', 'swim', 'switch', 'syndrome', 'system', 'table', 'take', 'taken', 'takes', 'taking', 'talent', 'talk', 'talking', 'tank', 'tastes', 'tattoo', 'taught', 'taylor', 'tea', 'teach', 'teachers', 'team', 'tears', 'teeth', 'tell', 'telling', 'temperature', 'tend', 'tennessee', 'term', 'terminator', 'terrible', 'tested', 'texas', 'text', 'thai', 'than', 'thank', 'thanks', 'that', 'the', 'theater', 'their', 'them', 'themselves', 'then', 'therapist', 'therapy', 'there', 'these', 'they', 'thing', 'things', 'think', 'thinking', 'thinks', 'thirsty', 'this', 'thomas', 'those', 'thought', 'thoughts', 'thread', 'threat', 'three', 'thrones', 'through', 'throughout', 'throwing', 'tight', 'tim', 'time', 'times', 'tired', 'tits', 'to', 'toasted', 'tobacco', 'today', 'toddler', 'toe', 'together', 'toilet', 'told', 'tomorrow', 'tonight', 'too', 'took', 'top', 'total', 'touch', 'tough', 'touring', 'town', 'track', 'traffic', 'train', 'trampoline', 'trans', 'treadmill', 'treasure', 'treat', 'treatment', 'tree', 'trick', 'tried', 'trouble', 'trousers', 'true', 'truly', 'trust', 'trusted', 'truth', 'try', 'trying', 'tuesday', 'tune', 'tuned', 'turn', 'turned', 'turning', 'turns', 'tv', 'tweet', 'tweets', 'twitter', 'two', 'type', 'ugly', 'un', 'unbelievable', 'under', 'understand', 'unfaithful', 'united', 'universe', 'university', 'unless', 'until', 'up', 'upset', 'upside', 'ur', 'us', 'use', 'used', 'using', 'valentine', 'value', 've', 'vegetable', 'very', 'vhs', 'vi', 'video', 'vinegar', 'violence', 'vision', 'visit', 'vitamin', 'voice', 'voices', 'wait', 'waiting', 'waits', 'wake', 'walk', 'walked', 'walkers', 'walking', 'walks', 'wall', 'walls', 'wanna', 'want', 'wanted', 'war', 'warm', 'wars', 'was', 'wasn', 'waste', 'watch', 'watched', 'watching', 'water', 'waving', 'way', 'ways', 'we', 'weakness', 'weapons', 'wear', 'wearing', 'web', 'webster', 'wedding', 'week', 'weekend', 'weeks', 'weight', 'weird', 'welcome', 'well', 'went', 'were', 'west', 'whales', 'what', 'whatever', 'wheelchair', 'when', 'whenever', 'where', 'which', 'while', 'white', 'whites', 'who', 'whole', 'whose', 'why', 'wife', 'will', 'willing', 'win', 'window', 'wine', 'winning', 'winter', 'wish', 'with', 'without', 'woman', 'women', 'won', 'woodchuck', 'wop', 'word', 'words', 'work', 'working', 'workout', 'world', 'worse', 'worst', 'worth', 'would', 'wouldn', 'wow', 'wrinkles', 'write', 'writer', 'writing', 'written', 'wrong', 'wrote', 'ya', 'yeah', 'year', 'years', 'yelling', 'yes', 'yesterday', 'yet', 'yo', 'yoda', 'yoghurt', 'you', 'young', 'younger', 'your', 'yourself', 'youth']\n",
      "(1000, 1500) (1000,)\n"
     ]
    }
   ],
   "source": [
    "## Extract features from data:\n",
    "\n",
    "# Create bag-of-words model (just for testing)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1500)\n",
    "X = vectorizer.fit_transform(corpus).toarray() # no. of features per phrase (phrase=row)\n",
    "y = dataset.loc[:,'is_humor'].values\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1500) (800,)\n",
      "(200, 1500) (200,)\n"
     ]
    }
   ],
   "source": [
    "## Split dataset into training and test sets (already done)\n",
    "### é melhor fazer assim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# second column of X represents the features\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text Classification\n",
    "\n",
    "#### Fit Naive Bayes to the training set (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Apply machine learning algorithms:\n",
    "\n",
    "##### SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predicted = classifier.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 44  36]\n",
      " [ 10 110]]\n",
      "Accuracy score:  0.77\n",
      "Precision score:  0.7534246575342466\n",
      "Recall:  0.9166666666666666\n",
      "F1:  0.8270676691729323\n"
     ]
    }
   ],
   "source": [
    "# Generate metrics (see prof example) to validate Model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(confusion_matrix(y_test, y_predicted))\n",
    "print('Accuracy score: ', accuracy_score(y_test, y_predicted))\n",
    "print('Precision score: ', precision_score(y_test, y_predicted))\n",
    "print('Recall: ', recall_score(y_test, y_predicted))\n",
    "print('F1: ', f1_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text: Life is depressing as hell.\n",
      "(1, 1500)\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "humor (+)\n"
     ]
    }
   ],
   "source": [
    "# Simple test\n",
    "\n",
    "sample_text = input(\"Enter text: \")\n",
    "X = vectorizer.transform([sample_text]).toarray()\n",
    "\n",
    "print(X.shape)\n",
    "print(X)\n",
    "\n",
    "if(classifier.predict(X) == [1]):\n",
    "    print('humor (+)')\n",
    "else:\n",
    "    print('not humor (-)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
